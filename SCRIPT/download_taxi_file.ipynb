{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pip install requests\n",
    "pip install beautifulsoup4\n",
    "pip install lxml\n",
    "pip install tqdm\n",
    "'''\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "import os\n",
    "from urllib.parse import urljoin\n",
    "import re\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# web page URL\n",
    "url = 'https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page'\n",
    "# Make a GET request to fetch the content of the page\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder where the downloaded files will be saved\n",
    "destination_directory = 'page_data/'\n",
    "# Specify the time intervals for which the files will be searched\n",
    "search_values = ['2023-06', '2022-06']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52.5M/52.5M [00:12<00:00, 4.26MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded file: yellow_tripdata_2023-06.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.49M/1.49M [00:01<00:00, 927kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded file: green_tripdata_2023-06.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13.4M/13.4M [00:05<00:00, 2.76MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded file: fhv_tripdata_2023-06.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476M/476M [01:53<00:00, 4.41MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded file: fhvhv_tripdata_2023-06.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52.8M/52.8M [00:12<00:00, 4.46MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded file: yellow_tripdata_2022-06.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.46M/1.46M [00:01<00:00, 883kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded file: green_tripdata_2022-06.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11.7M/11.7M [00:03<00:00, 3.44MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded file: fhv_tripdata_2022-06.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 437M/437M [02:21<00:00, 3.23MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded file: fhvhv_tripdata_2022-06.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Check if the request was completed successfully\n",
    "if response.status_code == 200:\n",
    "    # Parse the content of the page with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all <a> elements with the href attribute\n",
    "    links = soup.find_all('a', href=True)\n",
    "  \n",
    "\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    os.makedirs(destination_directory, exist_ok=True)\n",
    "\n",
    "    # Iterate through the links and download the files that meet the criteria\n",
    "    for link in links:\n",
    "        url_relative = link['href']\n",
    "        if url_relative.startswith(('http', 'https')):\n",
    "            # URL absolut\n",
    "            url_absolute = url_relative\n",
    "        else:\n",
    "            # Construct an absolute URL\n",
    "            url_absolute = urljoin(url, url_relative)\n",
    "        # Build the dynamic regular expression\n",
    "        regular_expression = '|'.join(map(re.escape, search_values))\n",
    "        # Check if the absolute URL contains the desired dates\n",
    "        if re.search(regular_expression, url_absolute):\n",
    "            # Extract the file name from the URL\n",
    "            file_name = url_relative.split('/')[-1]\n",
    "\n",
    "            # Download the file with a progress bar\n",
    "            response = requests.get(url_absolute, stream=True)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                save_path = os.path.join(destination_directory, file_name)\n",
    "                total_size = int(response.headers.get('content-length', 0))\n",
    "                with tqdm(total=total_size, unit='B', unit_scale=True, unit_divisor=1024) as pbar:\n",
    "                    with open(save_path, 'wb') as file:\n",
    "                        for data in response.iter_content(chunk_size=1024):\n",
    "                            pbar.update(len(data))\n",
    "                            file.write(data)\n",
    "                print(\"Downloaded file:\", file_name)\n",
    "            else:\n",
    "                print(\"The file could not be downloaded:\", file_name)\n",
    "\n",
    "else:\n",
    "    print(\"Page access error:\", response.status_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
